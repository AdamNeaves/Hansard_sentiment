@misc{,
title = {{Sentiment Analysis in Python with TextBlob and VADER Sentiment (also Dash p.6) - YouTube}},
url = {https://www.youtube.com/watch?v=qTyj2R-wcks},
urldate = {2018-03-01}
}
@misc{,
title = {{Word2Vec, Doc2vec {\&} GloVe: Neural Word Embeddings for Natural Language Processing - Deeplearning4j: Open-source, Distributed Deep Learning for the JVM}},
url = {https://deeplearning4j.org/word2vec.html},
urldate = {2018-03-01}
}
@article{Riedel2017,
abstract = {Identifying public misinformation is a complicated and challenging task. Stance detection, i.e. determining the relative perspective a news source takes towards a specific claim, is an important part of evaluating the veracity of the assertion. Automating the process of stance detection would arguably benefit human fact checkers. In this paper, we present our stance detection model which claimed third place in the first stage of the Fake News Challenge. Despite our straightforward approach, our model performs at a competitive level with the complex ensembles of the top two winning teams. We therefore propose our model as the 'simple but tough-to-beat baseline' for the Fake News Challenge stance detection task.},
archivePrefix = {arXiv},
arxivId = {1707.03264},
author = {Riedel, Benjamin and Augenstein, Isabelle and Spithourakis, Georgios P. and Riedel, Sebastian},
eprint = {1707.03264},
file = {:C$\backslash$:/Users/Adam Neaves/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Riedel et al. - 2017 - A simple but tough-to-beat baseline for the Fake News Challenge stance detection task.pdf:pdf},
month = {jul},
title = {{A simple but tough-to-beat baseline for the Fake News Challenge stance detection task}},
url = {http://arxiv.org/abs/1707.03264},
year = {2017}
}
@article{Augenstein2016,
abstract = {Stance detection is the task of classifying the attitude expressed in a text towards a target such as Hillary Clinton to be "positive", negative" or "neutral". Previous work has assumed that either the target is mentioned in the text or that training data for every target is given. This paper considers the more challenging version of this task, where targets are not always mentioned and no training data is available for the test targets. We experiment with conditional LSTM encoding, which builds a representation of the tweet that is dependent on the target, and demonstrate that it outperforms encoding the tweet and the target independently. Performance is improved further when the conditional model is augmented with bidirectional encoding. We evaluate our approach on the SemEval 2016 Task 6 Twitter Stance Detection corpus achieving performance second best only to a system trained on semi-automatically labelled tweets for the test target. When such weak supervision is added, our approach achieves state-of-the-art results.},
archivePrefix = {arXiv},
arxivId = {1606.05464},
author = {Augenstein, Isabelle and Rockt{\"{a}}schel, Tim and Vlachos, Andreas and Bontcheva, Kalina},
eprint = {1606.05464},
file = {:C$\backslash$:/Users/Adam Neaves/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Augenstein et al. - 2016 - Stance Detection with Bidirectional Conditional Encoding.pdf:pdf},
month = {jun},
title = {{Stance Detection with Bidirectional Conditional Encoding}},
url = {http://arxiv.org/abs/1606.05464},
year = {2016}
}
@article{Dori-Hacohen2015,
abstract = {Alerting users about controversial search results can encour- age critical literacy, promote healthy civic discourse and counteract the “filter bubble” effect. Additionally, present- ing information to the user about the different stances or sides of the debate can help her navigate the landscape of search results. Our existing work made strides in the emerg- ing niche of controversy detection and analysis; we propose further work on automatic stance detection.},
author = {Dori-Hacohen, Shiri},
doi = {10.1145/2766462.2767844},
file = {:C$\backslash$:/Users/Adam Neaves/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Dori-Hacohen - 2015 - Controversy Detection and Stance Analysis.pdf:pdf},
isbn = {9781450336215},
journal = {Proceedings of the 38th International ACM SIGIR Conference on Research and Development in Information Retrieval},
keywords = {controversy detection,critical literacy,stance detection},
pages = {1057--1057},
title = {{Controversy Detection and Stance Analysis}},
year = {2015}
}
@article{Ferreira,
abstract = {We present Emergent, a novel data-set de-rived from a digital journalism project for ru-mour debunking. The data-set contains 300 rumoured claims and 2,595 associated news articles, collected and labelled by journalists with an estimation of their veracity (true, false or unverified). Each associated article is sum-marized into a headline and labelled to indi-cate whether its stance is for, against, or ob-serving the claim, where observing indicates that the article merely repeats the claim. Thus, Emergent provides a real-world data source for a variety of natural language processing tasks in the context of fact-checking. Fur-ther to presenting the dataset, we address the task of determining the article headline stance with respect to the claim. For this purpose we use a logistic regression classifier and de-velop features that examine the headline and its agreement with the claim. The accuracy achieved was 73{\%} which is 26{\%} higher than the one achieved by the Excitement Open Plat-form (Magnini et al., 2014).},
author = {Ferreira, William and Vlachos, Andreas},
file = {:C$\backslash$:/Users/Adam Neaves/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Ferreira, Vlachos - Unknown - Emergent a novel data-set for stance classification.pdf:pdf},
pages = {1163--1168},
title = {{Emergent: a novel data-set for stance classification}},
url = {http://aclweb.org/anthology/N/N16/N16-1138.pdf}
}
@article{Aker2017,
abstract = {Stance classification determines the attitude, or stance, in a (typically short) text. The task has powerful applications, such as the detection of fake news or the automatic extraction of attitudes toward entities or events in the media. This paper describes a surprisingly simple and efficient classification approach to open stance classification in Twitter, for rumour and veracity classification. The approach profits from a novel set of automatically identifiable problem-specific features, which significantly boost classifier accuracy and achieve above state-of-the-art results on recent benchmark datasets. This calls into question the value of using complex sophisticated models for stance classification without first doing informed feature extraction.},
archivePrefix = {arXiv},
arxivId = {1708.05286},
author = {Aker, Ahmet and Derczynski, Leon and Bontcheva, Kalina},
eprint = {1708.05286},
file = {:C$\backslash$:/Users/Adam Neaves/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Aker, Derczynski, Bontcheva - 2017 - Simple Open Stance Classification for Rumour Analysis.pdf:pdf},
month = {aug},
title = {{Simple Open Stance Classification for Rumour Analysis}},
url = {http://arxiv.org/abs/1708.05286},
year = {2017}
}
@misc{Nagy2017,
author = {Nagy, Peter},
booktitle = {Kaggle},
title = {{Python NLTK Sentiment Analysis}},
url = {https://www.kaggle.com/ngyptr/python-nltk-sentiment-analysis/notebook},
urldate = {2018-02-12},
year = {2017}
}
@inproceedings{Onyimadu2014,
abstract = {This paper reports on our ongoing work on the analysis of sentiments, i.e., individual and collective stances, in Hansard (Hansard is a publicly available transcript of UK Parliamentary debates). Significant work has been carried out in the area of sentiment analysis particularly on reviews and social media but less so on political transcripts and debates. Parliamentary transcripts and debates are significantly different from blogs and reviews, e.g., the presence of sarcasm, interjections, irony and digression from the topic are commonplace increasing the complexity and difficulty in applying standard sentiment analysis techniques. In this paper we present our sentiment analysis methodology for parliamentary debate using known lexical and syntactic rules, word associations for the creation of a heuristic classifier capable of identifying sentiment carrying sentences and MP stance. {\textcopyright} 2014 Springer International Publishing.},
annote = {BLOODY CANT READ AT THE MOMENT CAUSE PAYWALLS},
author = {Onyimadu, Obinna and Nakata, Keiichi and Wilson, Tony and Macken, David and Liu, Kecheng},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-06826-8_4},
isbn = {9783319068251},
issn = {16113349},
keywords = {Hansard,Sentiment analysis},
pages = {48--50},
title = {{Towards sentiment analysis on parliamentary debates in Hansard}},
volume = {8388 LNCS},
year = {2014}
}
@incollection{Onyimadu2013,
author = {Onyimadu, Obinna and Nakata, Keiichi and Wang, Ying and Wilson, Tony and Liu, Kecheng},
doi = {10.1007/978-3-642-37996-3_27},
file = {:C$\backslash$:/Users/Adam Neaves/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Onyimadu et al. - 2013 - Entity-Based Semantic Search on Conversational Transcripts Semantic.pdf:pdf},
pages = {344--349},
publisher = {Springer, Berlin, Heidelberg},
title = {{Entity-Based Semantic Search on Conversational Transcripts Semantic}},
url = {http://link.springer.com/10.1007/978-3-642-37996-3{\_}27},
year = {2013}
}
@misc{Richardson,
annote = {Documentation for BeautifulSoup4, a HTML/XML parser for Python, which could be useful for dealing with the large badly formatted XML documents.},
author = {Richardson, Leonard},
title = {{Beautiful Soup Documentation}},
url = {https://www.crummy.com/software/BeautifulSoup/bs4/doc/},
urldate = {2018-02-10}
}
@misc{Perkins2010,
annote = {An online article that describes how the author trained a Naive Bayes classifier on movie reviews using the NLTK for Python. It should serve as a good reference when looking to do something similar.},
author = {Perkins, Jacob},
booktitle = {Stream Hacker},
title = {{Text Classification For Sentiment Analysis - Naive Bayes Classifier}},
url = {https://streamhacker.com/2010/05/10/text-classification-sentiment-analysis-naive-bayes-classifier/},
urldate = {2018-02-10},
year = {2010}
}
@book{Noble1988,
address = {Oxford},
annote = {This book provides a decent overview on Natural Language Processing for computer systems. It does not, however, mention any specifics for Sentiment Analysis.},
author = {Noble, H M},
edition = {1st},
editor = {Addis, Tom and DuBoulay, Ben and Tate, Austin},
isbn = {0632015020},
keywords = {Computer Science,Machine Learning,Natural Language Processing},
mendeley-tags = {Computer Science,Machine Learning,Natural Language Processing},
publisher = {Blackwell Scientific Publications},
title = {{Natural Language Processing}},
year = {1988}
}
@book{Bird2009,
abstract = {This book offers a highly accessible introduction to natural language processing, the field that supports a variety of language technologies, from predictive text and email filtering to automatic summarization and translation. With it, you'll learn how to write Python programs that work with large collections of unstructured text. You'll access richly annotated datasets using a comprehensive range of linguistic data structures, and you'll understand the main algorithms for analyzing the content and structure of written communication. Packed with examples and exercises, Natural Language Processing with Python will help you:Extract information from unstructured text, either to guess the topic or identify "named entities" Analyze linguistic structure in text, including parsing and semantic analysis Access popular linguistic databases, including WordNet and treebanks Integrate techniques drawn from fields as diverse as linguistics and artificial intelligence This book will help you gain practical skills in natural language processing using the Python programming language and the Natural Language Toolkit (NLTK) open source library. If you're interested in developing web applications, analyzing multilingual news sources, or documenting endangered languages - or if you're simply curious to have a programmer's perspective on how human language works - you'll find Natural Language Processing with Python both fascinating and immensely useful.},
annote = {A guide to the Natural Language Toolkit for Python, a specific package that may be used for the project.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Bird, Steven and Klein, Ewan and Loper, Edward},
booktitle = {Text},
doi = {10.1097/00004770-200204000-00018},
edition = {1st},
eprint = {arXiv:1011.1669v3},
isbn = {9780596516499},
issn = {00992399},
pages = {479},
pmid = {12043876},
title = {{Natural Language Processing with Python}},
url = {http://www.amazon.com/dp/0596516495},
volume = {43},
year = {2009}
}
