@misc{MySociety,
abstract = {TheyWorkForYou is a website which makes it easy to keep track of your local MP's activities.},
author = {MySociety},
keywords = {Charity,Politics},
title = {{TheyWorkForYou: Hansard and Official Reports for the UK Parliament, Scottish Parliament, and Northern Ireland Assembly - done right}},
url = {https://www.theyworkforyou.com/ http://www.theyworkforyou.com/},
urldate = {2018-04-18}
}
@misc{FakeNewsChallenge2017,
abstract = {fake news challenge},
author = {{Fake News Challenge}},
title = {{Fake News Challenge}},
url = {http://www.fakenewschallenge.org/ www.fakenewschallenge.org},
year = {2017}
}
@article{HouseofCommonsInformationOffice2010,
author = {{House of Commons Information Office}},
file = {:C$\backslash$:/Users/Adam Neaves/AppData/Local/Mendeley Ltd./Mendeley Desktop/Downloaded/Unknown - 2010 - Factsheet G17 General Series The Official Report.pdf:pdf},
journal = {The Official Report},
number = {August},
title = {{Factsheet G17: The Official Report}},
url = {https://www.parliament.uk/documents/commons-information-office/g17.pdf},
year = {2010}
}
@inproceedings{Onyimadu2014,
abstract = {This paper reports on our ongoing work on the analysis of sentiments, i.e., individual and collective stances, in Hansard (Hansard is a publicly available transcript of UK Parliamentary debates). Significant work has been carried out in the area of sentiment analysis particularly on reviews and social media but less so on political transcripts and debates. Parliamentary transcripts and debates are significantly different from blogs and reviews, e.g., the presence of sarcasm, interjections, irony and digression from the topic are commonplace increasing the complexity and difficulty in applying standard sentiment analysis techniques. In this paper we present our sentiment analysis methodology for parliamentary debate using known lexical and syntactic rules, word associations for the creation of a heuristic classifier capable of identifying sentiment carrying sentences and MP stance. {\textcopyright} 2014 Springer International Publishing.},
annote = {BLOODY CANT READ AT THE MOMENT CAUSE PAYWALLS},
author = {Onyimadu, Obinna and Nakata, Keiichi and Wilson, Tony and Macken, David and Liu, Kecheng},
booktitle = {Lecture Notes in Computer Science (including subseries Lecture Notes in Artificial Intelligence and Lecture Notes in Bioinformatics)},
doi = {10.1007/978-3-319-06826-8_4},
isbn = {9783319068251},
issn = {16113349},
keywords = {Hansard,Sentiment analysis},
pages = {48--50},
title = {{Towards sentiment analysis on parliamentary debates in Hansard}},
volume = {8388 LNCS},
year = {2014}
}
@book{Noble1988,
address = {Oxford},
annote = {This book provides a decent overview on Natural Language Processing for computer systems. It does not, however, mention any specifics for Sentiment Analysis.},
author = {Noble, H M},
edition = {1st},
editor = {Addis, Tom and DuBoulay, Ben and Tate, Austin},
isbn = {0632015020},
keywords = {Computer Science,Machine Learning,Natural Language Processing},
mendeley-tags = {Computer Science,Machine Learning,Natural Language Processing},
publisher = {Blackwell Scientific Publications},
title = {{Natural Language Processing}},
year = {1988}
}
@book{Bird2009,
abstract = {This book offers a highly accessible introduction to natural language processing, the field that supports a variety of language technologies, from predictive text and email filtering to automatic summarization and translation. With it, you'll learn how to write Python programs that work with large collections of unstructured text. You'll access richly annotated datasets using a comprehensive range of linguistic data structures, and you'll understand the main algorithms for analyzing the content and structure of written communication. Packed with examples and exercises, Natural Language Processing with Python will help you:Extract information from unstructured text, either to guess the topic or identify "named entities" Analyze linguistic structure in text, including parsing and semantic analysis Access popular linguistic databases, including WordNet and treebanks Integrate techniques drawn from fields as diverse as linguistics and artificial intelligence This book will help you gain practical skills in natural language processing using the Python programming language and the Natural Language Toolkit (NLTK) open source library. If you're interested in developing web applications, analyzing multilingual news sources, or documenting endangered languages - or if you're simply curious to have a programmer's perspective on how human language works - you'll find Natural Language Processing with Python both fascinating and immensely useful.},
annote = {A guide to the Natural Language Toolkit for Python, a specific package that may be used for the project.},
archivePrefix = {arXiv},
arxivId = {arXiv:1011.1669v3},
author = {Bird, Steven and Klein, Ewan and Loper, Edward},
booktitle = {Text},
doi = {10.1097/00004770-200204000-00018},
edition = {1st},
eprint = {arXiv:1011.1669v3},
isbn = {9780596516499},
issn = {00992399},
pages = {479},
pmid = {12043876},
title = {{Natural Language Processing with Python}},
url = {http://www.amazon.com/dp/0596516495},
volume = {43},
year = {2009}
}
@misc{Richardson,
annote = {Documentation for BeautifulSoup4, a HTML/XML parser for Python, which could be useful for dealing with the large badly formatted XML documents.},
author = {Richardson, Leonard},
title = {{Beautiful Soup Documentation}},
url = {https://www.crummy.com/software/BeautifulSoup/bs4/doc/},
urldate = {2018-02-10}
}
